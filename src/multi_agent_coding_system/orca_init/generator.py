"""Config file generator for Orca Init.

This module generates the .orca/ directory contents from analysis results.
"""

import os
import yaml
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any

from multi_agent_coding_system.orca_init.analyzer import CodebaseAnalysis
from multi_agent_coding_system.orca_init.detector import PatternDetectionResult, PatternInfo


@dataclass
class GeneratedConfig:
    """Collection of generated configuration files."""
    project_yaml: str = ""
    architecture_md: str = ""
    vocabulary_yaml: str = ""
    patterns: Dict[str, str] = field(default_factory=dict)  # pattern_name -> content


def generate_config(
    analysis: CodebaseAnalysis,
    detection: PatternDetectionResult,
    user_inputs: Optional[Dict[str, Any]] = None,
) -> GeneratedConfig:
    """Generate .orca/ configuration from analysis results.

    Args:
        analysis: Codebase structure analysis
        detection: Pattern detection results
        user_inputs: Optional user-provided refinements

    Returns:
        GeneratedConfig with all file contents
    """
    user_inputs = user_inputs or {}
    config = GeneratedConfig()

    # Generate project.yaml
    config.project_yaml = _generate_project_yaml(analysis, user_inputs)

    # Generate architecture.md
    config.architecture_md = _generate_architecture_md(analysis, detection, user_inputs)

    # Generate vocabulary.yaml
    config.vocabulary_yaml = _generate_vocabulary_yaml(detection, user_inputs)

    # Generate pattern documentation
    for pattern in detection.patterns:
        if pattern.pattern_type in ("mixin", "base_class"):
            pattern_name = _normalize_pattern_name(pattern.name)
            config.patterns[pattern_name] = _generate_pattern_doc(
                pattern, analysis, detection
            )

    return config


def _generate_project_yaml(
    analysis: CodebaseAnalysis,
    user_inputs: Dict[str, Any],
) -> str:
    """Generate project.yaml content."""
    config = {
        "name": user_inputs.get("project_name", analysis.project_name),
        "description": user_inputs.get(
            "description",
            f"# TODO: Add project description\n"
            f"# Detected: {analysis.primary_language} project with {', '.join(analysis.frameworks[:3]) or 'no detected frameworks'}"
        ),
        "tech_stack": analysis.frameworks + analysis.languages[:3],
        "entry_points": analysis.entry_points[:5],
    }

    if analysis.source_directories:
        config["directories"] = {
            "source": analysis.source_directories[0] if analysis.source_directories else "src",
        }
        if analysis.test_directories:
            config["directories"]["tests"] = analysis.test_directories[0]

    if analysis.test_directories:
        test_framework = "pytest" if "Python" in analysis.languages else "vitest"
        config["testing"] = {
            "framework": test_framework,
            "test_dir": analysis.test_directories[0] if analysis.test_directories else "tests",
            "run_command": "pytest -q" if test_framework == "pytest" else "npm test",
        }

    # Format as YAML with comments
    lines = [
        "# Project configuration for multi-agent system",
        "# Generated by orca-init - customize as needed",
        "",
    ]

    # Add YAML content with nice formatting
    yaml_content = yaml.dump(config, default_flow_style=False, sort_keys=False, allow_unicode=True)
    lines.append(yaml_content)

    return "\n".join(lines)


def _generate_architecture_md(
    analysis: CodebaseAnalysis,
    detection: PatternDetectionResult,
    user_inputs: Dict[str, Any],
) -> str:
    """Generate architecture.md content."""
    lines = [
        f"# {analysis.project_name} Architecture",
        "",
        "## Overview",
        "",
        f"<!-- TODO: Add project overview -->",
        f"This is a {analysis.primary_language} project",
        f"using {', '.join(analysis.frameworks[:5]) if analysis.frameworks else 'standard libraries'}.",
        "",
        "## Project Structure",
        "",
        "```",
        f"{analysis.project_name}/",
    ]

    # Add directory structure
    for src_dir in analysis.source_directories[:5]:
        lines.append(f"├── {src_dir}/")
    for test_dir in analysis.test_directories[:3]:
        lines.append(f"├── {test_dir}/")
    if analysis.config_files:
        lines.append(f"├── {analysis.config_files[0]}")
    lines.append("└── ...")
    lines.append("```")
    lines.append("")

    # Add detected patterns section
    if detection.patterns:
        lines.append("## Key Patterns")
        lines.append("")

        mixin_patterns = [p for p in detection.patterns if p.pattern_type == "mixin"]
        base_patterns = [p for p in detection.patterns if p.pattern_type == "base_class"]

        if mixin_patterns:
            lines.append("### Mixins")
            lines.append("")
            lines.append("The codebase uses mixin composition for reusable functionality:")
            lines.append("")
            for pattern in mixin_patterns[:5]:
                lines.append(f"- **{pattern.name}**: {pattern.description}")
            lines.append("")

        if base_patterns:
            lines.append("### Base Classes")
            lines.append("")
            for pattern in base_patterns[:5]:
                lines.append(f"- **{pattern.name}**: {pattern.description}")
                if pattern.related_classes:
                    lines.append(f"  - Implementations: {', '.join(pattern.related_classes[:3])}")
            lines.append("")

    # Add module dependencies section
    lines.extend([
        "## Module Dependencies",
        "",
        "<!-- TODO: Document key module dependencies -->",
        "",
        "```",
        "# Example dependency flow:",
        "# strategies/ -> mixins/ -> data/",
        "```",
        "",
        "## Critical Paths",
        "",
        "<!-- TODO: Identify and document critical code paths -->",
        "",
        "The following are high-priority areas for code quality:",
        "",
        "1. **TODO**: Add critical path 1",
        "2. **TODO**: Add critical path 2",
        "",
    ])

    return "\n".join(lines)


def _generate_vocabulary_yaml(
    detection: PatternDetectionResult,
    user_inputs: Dict[str, Any],
) -> str:
    """Generate vocabulary.yaml content."""
    lines = [
        "# Domain vocabulary for the project",
        "# Generated by orca-init - add definitions and examples",
        "",
    ]

    vocab_dict = {}

    # Add detected vocabulary terms
    for term in detection.vocabulary[:30]:  # Top 30 terms
        # Create entry with placeholder definition
        vocab_dict[term.term] = {
            "definition": f"# TODO: Define '{term.term}' (found {term.occurrences} times)",
            "examples": [],
        }

    # Add pattern-specific terms
    for pattern in detection.patterns:
        if pattern.name not in vocab_dict:
            vocab_dict[pattern.name] = {
                "definition": pattern.description,
                "examples": pattern.example_files[:2],
                "see_also": pattern.related_classes[:3],
            }

    # Format as YAML
    yaml_content = yaml.dump(vocab_dict, default_flow_style=False, sort_keys=False, allow_unicode=True)
    lines.append(yaml_content)

    return "\n".join(lines)


def _generate_pattern_doc(
    pattern: PatternInfo,
    analysis: CodebaseAnalysis,
    detection: PatternDetectionResult,
) -> str:
    """Generate pattern documentation markdown."""
    lines = [
        "---",
        f"description: {pattern.description}",
        "examples:",
    ]
    for example in pattern.example_files[:3]:
        lines.append(f"  - {example}")
    lines.extend([
        "related_files:",
    ])
    for example in pattern.example_files[:3]:
        lines.append(f"  - {example}")
    lines.extend([
        "---",
        "",
        f"# Implementing {pattern.name}",
        "",
        f"<!-- TODO: Add implementation guide for {pattern.name} -->",
        "",
        "## Overview",
        "",
        f"{pattern.description}",
        "",
    ])

    if pattern.related_classes:
        lines.append("## Existing Implementations")
        lines.append("")
        for cls in pattern.related_classes[:5]:
            lines.append(f"- `{cls}`")
        lines.append("")

    if pattern.pattern_type == "mixin":
        lines.extend([
            "## Implementation Pattern",
            "",
            "```python",
            f"# TODO: Add base class and implementation example",
            f"class {pattern.name}Base:",
            "    '''Base class for this pattern.'''",
            "    pass",
            "",
            f"class My{pattern.name}({pattern.name}Base):",
            "    '''Example implementation.'''",
            "    pass",
            "```",
            "",
            "## Requirements",
            "",
            "When implementing this pattern:",
            "",
            "1. **TODO**: Add requirement 1",
            "2. **TODO**: Add requirement 2",
            "",
            "## Testing",
            "",
            "```python",
            "# TODO: Add testing example",
            "def test_example():",
            "    pass",
            "```",
            "",
        ])

    return "\n".join(lines)


def _normalize_pattern_name(name: str) -> str:
    """Normalize pattern name for use as filename."""
    # Convert CamelCase to snake_case
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()


def write_config(config: GeneratedConfig, output_dir: str) -> List[str]:
    """Write generated config to the .orca/ directory.

    Args:
        config: Generated configuration
        output_dir: Path to project root

    Returns:
        List of created file paths
    """
    orca_dir = Path(output_dir) / ".orca"
    orca_dir.mkdir(exist_ok=True)

    created_files = []

    # Write project.yaml
    project_path = orca_dir / "project.yaml"
    project_path.write_text(config.project_yaml)
    created_files.append(str(project_path))

    # Write architecture.md
    arch_path = orca_dir / "architecture.md"
    arch_path.write_text(config.architecture_md)
    created_files.append(str(arch_path))

    # Write vocabulary.yaml
    vocab_path = orca_dir / "vocabulary.yaml"
    vocab_path.write_text(config.vocabulary_yaml)
    created_files.append(str(vocab_path))

    # Write patterns
    if config.patterns:
        patterns_dir = orca_dir / "patterns"
        patterns_dir.mkdir(exist_ok=True)

        for pattern_name, content in config.patterns.items():
            pattern_path = patterns_dir / f"{pattern_name}.md"
            pattern_path.write_text(content)
            created_files.append(str(pattern_path))

    return created_files


def generate_orca_config(
    output_dir: str,
    analysis: CodebaseAnalysis,
    detection: PatternDetectionResult,
    user_inputs: Optional[Dict[str, Any]] = None,
) -> List[str]:
    """Generate and write .orca/ configuration in one step.

    This is a convenience function that combines generate_config() and write_config().

    Args:
        output_dir: Path to project root where .orca/ will be created
        analysis: Codebase structure analysis
        detection: Pattern detection results
        user_inputs: Optional user-provided refinements

    Returns:
        List of created file paths
    """
    config = generate_config(analysis, detection, user_inputs)
    return write_config(config, output_dir)
